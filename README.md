# Towards Visual Text Grounding of Multimodal Large Language Model

[Towards visual text grounding of multimodal large language model](https://arxiv.org/abs/2504.04974) <br>
Reasoning and Planning for LLMs @ ICLR2025 || ICLR 2025 Workshop SynthData

This is the repo for the TRIG project, which introduces the task of **Text-Rich Image Grounding (TRIG)** for LMMLs. <br>

This repo mainly contains the benchmark data for TRIG and the corresponding minimal evaluation scripts. 
